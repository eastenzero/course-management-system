# file: data-generator/test_mega_generation.py
# åŠŸèƒ½: ç™¾ä¸‡çº§æ•°æ®ç”Ÿæˆç³»ç»Ÿæµ‹è¯•

import sys
import time
import shutil
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from mega_scale.mega_generator import MegaDataGenerator, MegaGenerationConfig
from performance_monitor import create_performance_dashboard


def test_basic_functionality():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½éªŒè¯")
    print("-" * 50)
    
    try:
        # å°è§„æ¨¡æµ‹è¯•é…ç½®
        config = MegaGenerationConfig(
            target_records=10000,  # 1ä¸‡æ¡è®°å½•
            batch_size=2000,
            max_memory_mb=512,
            max_workers=2,
            enable_compression=False,
            enable_streaming=True
        )
        
        generator = MegaDataGenerator(config)
        
        print("   âœ… ç”Ÿæˆå™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–
        generator._initialize_system()
        print("   âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸…ç†
        generator._cleanup_resources()
        print("   âœ… èµ„æºæ¸…ç†æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"   âŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_batch_processing():
    """æµ‹è¯•æ‰¹å¤„ç†åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•2: æ‰¹å¤„ç†åŠŸèƒ½éªŒè¯")
    print("-" * 50)
    
    try:
        from mega_scale.batch_manager import BatchProcessingManager, BatchConfig
        
        config = BatchConfig(
            batch_size=1000,
            max_memory_mb=256,
            max_workers=2
        )
        
        manager = BatchProcessingManager(config)
        
        # æµ‹è¯•æ‰¹æ¬¡åˆ›å»º
        batches = manager.create_batches(5000)
        print(f"   âœ… åˆ›å»ºæ‰¹æ¬¡: {len(batches)} ä¸ª")
        
        # æµ‹è¯•æœ€ä¼˜æ‰¹æ¬¡å¤§å°è®¡ç®—
        optimal_size = manager.calculate_optimal_batch_size(10000)
        print(f"   âœ… æœ€ä¼˜æ‰¹æ¬¡å¤§å°: {optimal_size}")
        
        # æµ‹è¯•è¿›åº¦æ‘˜è¦
        summary = manager.get_progress_summary()
        print(f"   âœ… è¿›åº¦æ‘˜è¦è·å–æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"   âŒ æ‰¹å¤„ç†åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_memory_optimization():
    """æµ‹è¯•å†…å­˜ä¼˜åŒ–åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•3: å†…å­˜ä¼˜åŒ–åŠŸèƒ½éªŒè¯")
    print("-" * 50)
    
    try:
        from mega_scale.memory_optimizer import MemoryOptimizer
        
        optimizer = MemoryOptimizer(max_memory_mb=512)
        
        # æµ‹è¯•å†…å­˜ç›‘æ§
        memory_usage = optimizer.get_memory_usage_mb()
        print(f"   âœ… å½“å‰å†…å­˜ä½¿ç”¨: {memory_usage:.1f}MB")
        
        # æµ‹è¯•åƒåœ¾å›æ”¶
        freed = optimizer.force_gc()
        print(f"   âœ… åƒåœ¾å›æ”¶é‡Šæ”¾: {freed:.1f}MB")
        
        # æµ‹è¯•å¤§è§„æ¨¡ä¼˜åŒ–å»ºè®®
        recommendations = optimizer.optimize_for_large_scale(100000)
        print(f"   âœ… ä¼˜åŒ–å»ºè®®: {len(recommendations['optimizations_applied'])} é¡¹")
        
        # æµ‹è¯•æµå¼å†™å…¥
        test_file = "test_stream_output.json"
        optimizer.write_incrementally(test_file, {"test": "data"})
        print("   âœ… æµå¼å†™å…¥æµ‹è¯•æˆåŠŸ")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        Path(test_file).unlink(missing_ok=True)
        
        optimizer.cleanup()
        return True
        
    except Exception as e:
        print(f"   âŒ å†…å­˜ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_parallel_engine():
    """æµ‹è¯•å¹¶è¡Œè®¡ç®—å¼•æ“"""
    print("\nğŸ§ª æµ‹è¯•4: å¹¶è¡Œè®¡ç®—å¼•æ“éªŒè¯")
    print("-" * 50)
    
    try:
        from mega_scale.parallel_engine import ParallelComputingEngine, TaskConfig
        
        engine = ParallelComputingEngine(max_workers=2)
        engine.initialize_workers(process_workers=1, thread_workers=1)
        engine.start_processing()
        
        # æ³¨å†Œæµ‹è¯•ä»»åŠ¡å‡½æ•°
        def test_task(start, end, multiplier=1):
            return [(i * multiplier) for i in range(start, end)]
        
        engine.register_task_function('test_task', test_task)
        
        # æäº¤æµ‹è¯•ä»»åŠ¡
        task_config = TaskConfig(
            task_id="test_task_1",
            task_type="test_task",
            priority=5,
            estimated_duration=1.0
        )
        
        task_id = engine.submit_task(task_config, test_task, 1, 10, multiplier=2)
        print(f"   âœ… ä»»åŠ¡æäº¤æˆåŠŸ: {task_id}")
        
        # ç­‰å¾…å®Œæˆ
        completed = engine.wait_for_completion(timeout=10.0)
        print(f"   âœ… ä»»åŠ¡å®ŒæˆçŠ¶æ€: {completed}")
        
        # è·å–ç»“æœ
        results = engine.get_results()
        if task_id in results:
            print(f"   âœ… ä»»åŠ¡ç»“æœè·å–æˆåŠŸ")
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        stats = engine.get_performance_stats()
        print(f"   âœ… æ€§èƒ½ç»Ÿè®¡: å¤„ç†ä»»åŠ¡ {stats['total_tasks_processed']} ä¸ª")
        
        engine.stop()
        return True
        
    except Exception as e:
        print(f"   âŒ å¹¶è¡Œè®¡ç®—å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_progress_monitoring():
    """æµ‹è¯•è¿›åº¦ç›‘æ§åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•5: è¿›åº¦ç›‘æ§åŠŸèƒ½éªŒè¯")
    print("-" * 50)
    
    try:
        from mega_scale.progress_monitor import ProgressMonitor
        
        monitor = ProgressMonitor(total_records=1000)
        monitor.start_monitoring(enable_progress_bar=False)
        
        # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
        for i in range(0, 1001, 100):
            monitor.update_progress(i)
            time.sleep(0.1)
        
        # æµ‹è¯•é”™è¯¯å¤„ç†
        try:
            raise ValueError("æµ‹è¯•é”™è¯¯")
        except Exception as e:
            error_id = monitor.handle_error(e, {'test': True})
            print(f"   âœ… é”™è¯¯å¤„ç†æˆåŠŸ: {error_id}")
        
        # è·å–çŠ¶æ€æŠ¥å‘Š
        report = monitor.get_status_report()
        print(f"   âœ… çŠ¶æ€æŠ¥å‘Šè·å–æˆåŠŸ")
        
        monitor.stop_monitoring()
        return True
        
    except Exception as e:
        print(f"   âŒ è¿›åº¦ç›‘æ§åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_performance_monitoring():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•6: æ€§èƒ½ç›‘æ§åŠŸèƒ½éªŒè¯")
    print("-" * 50)
    
    try:
        monitor = create_performance_dashboard()
        monitor.start_monitoring()
        
        # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ
        for i in range(5):
            monitor.update_generation_metrics(i * 1000)
            time.sleep(0.5)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = monitor.get_current_stats()
        print(f"   âœ… æ€§èƒ½ç»Ÿè®¡è·å–æˆåŠŸ")
        
        # è·å–è¶‹åŠ¿æ•°æ®
        trends = monitor.get_performance_trends()
        print(f"   âœ… è¶‹åŠ¿æ•°æ®è·å–æˆåŠŸ: {len(trends['timestamps'])} ä¸ªå¿«ç…§")
        
        monitor.stop_monitoring()
        return True
        
    except Exception as e:
        print(f"   âŒ æ€§èƒ½ç›‘æ§åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_configuration_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\nğŸ§ª æµ‹è¯•7: é…ç½®æ–‡ä»¶åŠ è½½éªŒè¯")
    print("-" * 50)
    
    try:
        import yaml
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        config_file = "mega_scale_config.yml"
        if not Path(config_file).exists():
            print(f"   âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return False
        
        # åŠ è½½é…ç½®
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        print(f"   âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # éªŒè¯å…³é”®é…ç½®é¡¹
        required_sections = ['generation', 'batch_processing', 'memory_optimization', 'output']
        for section in required_sections:
            if section in config:
                print(f"   âœ… é…ç½®æ®µ '{section}' å­˜åœ¨")
            else:
                print(f"   âŒ é…ç½®æ®µ '{section}' ç¼ºå¤±")
                return False
        
        return True
        
    except Exception as e:
        print(f"   âŒ é…ç½®æ–‡ä»¶åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_small_scale_generation():
    """æµ‹è¯•å°è§„æ¨¡æ•°æ®ç”Ÿæˆ"""
    print("\nğŸ§ª æµ‹è¯•8: å°è§„æ¨¡æ•°æ®ç”ŸæˆéªŒè¯")
    print("-" * 50)
    
    try:
        # å°è§„æ¨¡é…ç½®
        config = MegaGenerationConfig(
            target_records=5000,  # 5åƒæ¡è®°å½•
            batch_size=1000,
            max_memory_mb=512,
            max_workers=2,
            enable_compression=False,
            enable_streaming=True,
            output_formats=['json']
        )
        
        generator = MegaDataGenerator(config)
        
        # åˆ›å»ºæµ‹è¯•è¾“å‡ºç›®å½•
        test_output_dir = "test_mega_output"
        if Path(test_output_dir).exists():
            shutil.rmtree(test_output_dir)
        
        print("   ğŸš€ å¼€å§‹å°è§„æ¨¡æ•°æ®ç”Ÿæˆ...")
        start_time = time.time()
        
        results = generator.generate_mega_dataset(
            scale='small',
            output_dir=test_output_dir,
            conflict_difficulty='simple'
        )
        
        end_time = time.time()
        
        if results and results.get('success'):
            stats = results.get('performance_stats', {})
            total_records = stats.get('total_records', 0)
            
            print(f"   âœ… æ•°æ®ç”ŸæˆæˆåŠŸ!")
            print(f"   ğŸ“Š æ€»è®°å½•æ•°: {total_records:,}")
            print(f"   â±ï¸ è€—æ—¶: {end_time - start_time:.1f} ç§’")
            print(f"   ğŸš€ å¹³å‡é€Ÿåº¦: {total_records/(end_time - start_time):.0f} æ¡/ç§’")
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            output_path = Path(test_output_dir)
            if output_path.exists():
                output_files = list(output_path.glob("*.json"))
                print(f"   ğŸ“ ç”Ÿæˆæ–‡ä»¶: {len(output_files)} ä¸ª")
            
            return True
        else:
            print("   âŒ æ•°æ®ç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"   âŒ å°è§„æ¨¡æ•°æ®ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        test_output_dir = "test_mega_output"
        if Path(test_output_dir).exists():
            try:
                shutil.rmtree(test_output_dir)
                print("   ğŸ§¹ æµ‹è¯•æ–‡ä»¶æ¸…ç†å®Œæˆ")
            except:
                pass


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª ç™¾ä¸‡çº§æ•°æ®ç”Ÿæˆç³»ç»ŸåŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    
    tests = [
        ("åŸºæœ¬åŠŸèƒ½", test_basic_functionality),
        ("æ‰¹å¤„ç†åŠŸèƒ½", test_batch_processing),
        ("å†…å­˜ä¼˜åŒ–", test_memory_optimization),
        ("å¹¶è¡Œè®¡ç®—å¼•æ“", test_parallel_engine),
        ("è¿›åº¦ç›‘æ§", test_progress_monitoring),
        ("æ€§èƒ½ç›‘æ§", test_performance_monitoring),
        ("é…ç½®æ–‡ä»¶åŠ è½½", test_configuration_loading),
        ("å°è§„æ¨¡æ•°æ®ç”Ÿæˆ", test_small_scale_generation)
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            if result:
                passed += 1
                print(f"âœ… {test_name} - é€šè¿‡")
            else:
                failed += 1
                print(f"âŒ {test_name} - å¤±è´¥")
        except Exception as e:
            failed += 1
            print(f"âŒ {test_name} - å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 80)
    print(f"ğŸ§ª æµ‹è¯•æ±‡æ€»: é€šè¿‡ {passed} é¡¹, å¤±è´¥ {failed} é¡¹")
    
    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! ç™¾ä¸‡çº§æ•°æ®ç”Ÿæˆç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
        return True
    else:
        print(f"âš ï¸ æœ‰ {failed} é¡¹æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1)