# file: data-generator/realistic_course_generator.py
# åŠŸèƒ½: çœŸå®è¯¾ç¨‹æ•°æ®ç”Ÿæˆå™¨ä¸»ç¨‹åº

import sys
import logging
import argparse
import json
import time
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ ç”Ÿæˆå™¨æ¨¡å—è·¯å¾„
sys.path.append(str(Path(__file__).parent / 'generators'))

from constraint_aware_generator import ConstraintAwareCourseGenerator, GenerationConfig, GenerationMode
from mega_scale_processor import MegaScaleDataGenerator, BatchConfig, ProcessingMode, MemoryStrategy
from data_quality_validator import DataQualityAssessment
from course_scheduling_constraints import CourseRealismValidator
from teacher_course_matching import generate_realistic_teacher_profiles


def setup_logging(log_level: str = "INFO") -> logging.Logger:
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('course_generation.log', encoding='utf-8')
        ]
    )
    return logging.getLogger(__name__)


def create_generation_config(args) -> GenerationConfig:
    """åˆ›å»ºç”Ÿæˆé…ç½®"""
    return GenerationConfig(
        target_students=args.students,
        target_teachers=args.teachers,
        target_courses=args.courses,
        target_schedules=args.schedules,
        
        enable_prerequisite_constraints=not args.disable_prerequisites,
        enable_time_conflict_detection=not args.disable_time_conflicts,
        enable_capacity_constraints=not args.disable_capacity,
        enable_teacher_workload_limits=not args.disable_workload,
        
        realism_level=args.realism_level,
        constraint_strictness=args.constraint_strictness,
        semester_count=args.semesters,
        
        departments=[
            'è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢', 'æ•°å­¦ä¸ç»Ÿè®¡å­¦é™¢', 'ç‰©ç†ä¸ç”µå­å­¦é™¢',
            'å¤–å›½è¯­å­¦é™¢', 'ç»æµç®¡ç†å­¦é™¢', 'æœºæ¢°å·¥ç¨‹å­¦é™¢'
        ],
        
        generation_mode=GenerationMode.BALANCED
    )


def create_batch_config(args) -> BatchConfig:
    """åˆ›å»ºæ‰¹å¤„ç†é…ç½®"""
    return BatchConfig(
        batch_size=args.batch_size,
        max_memory_mb=args.max_memory,
        memory_threshold=args.memory_threshold,
        gc_frequency=args.gc_frequency,
        checkpoint_interval=args.checkpoint_interval,
        compression_enabled=not args.disable_compression,
        
        max_workers=args.workers,
        processing_mode=ProcessingMode.HYBRID,
        memory_strategy=MemoryStrategy.BALANCED,
        
        enable_object_pool=True,
        enable_streaming=True,
        
        checkpoint_dir="checkpoints",
        auto_resume=args.auto_resume,
        cleanup_checkpoints=True
    )


def generate_realistic_course_data(generation_config: GenerationConfig, 
                                 batch_config: BatchConfig,
                                 output_dir: str,
                                 logger: logging.Logger) -> Dict[str, Any]:
    """ç”ŸæˆçœŸå®çš„è¯¾ç¨‹æ•°æ®"""
    
    logger.info("="*80)
    logger.info("ğŸ“ çœŸå®è¯¾ç¨‹æ•°æ®ç”Ÿæˆç³»ç»Ÿå¯åŠ¨")
    logger.info("="*80)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    logger.info(f"ğŸ“Š ç›®æ ‡è§„æ¨¡:")
    logger.info(f"   å­¦ç”Ÿæ•°é‡: {generation_config.target_students:,}")
    logger.info(f"   æ•™å¸ˆæ•°é‡: {generation_config.target_teachers:,}")
    logger.info(f"   è¯¾ç¨‹æ•°é‡: {generation_config.target_courses:,}")
    logger.info(f"   æ’è¯¾è®°å½•: {generation_config.target_schedules:,}")
    
    logger.info(f"âš™ï¸ å¤„ç†é…ç½®:")
    logger.info(f"   æ‰¹æ¬¡å¤§å°: {batch_config.batch_size:,}")
    logger.info(f"   æœ€å¤§å†…å­˜: {batch_config.max_memory_mb}MB")
    logger.info(f"   å·¥ä½œè¿›ç¨‹: {batch_config.max_workers}")
    logger.info(f"   å¤„ç†æ¨¡å¼: {batch_config.processing_mode.value}")
    
    start_time = time.time()
    
    try:
        # åˆ¤æ–­æ˜¯å¦éœ€è¦å¤§è§„æ¨¡å¤„ç†
        if generation_config.target_students >= 50000:
            logger.info("ğŸš€ å¯åŠ¨ç™¾ä¸‡çº§æ•°æ®ç”Ÿæˆæ¨¡å¼...")
            generator = MegaScaleDataGenerator(generation_config, batch_config)
            result = generator.generate_mega_dataset(output_dir)
        else:
            logger.info("ğŸ¯ å¯åŠ¨æ ‡å‡†æ•°æ®ç”Ÿæˆæ¨¡å¼...")
            generator = ConstraintAwareCourseGenerator(generation_config)
            result = generator.generate_complete_dataset()
            
            # ä¿å­˜ç»“æœ
            output_path = Path(output_dir)
            output_path.mkdir(exist_ok=True)
            
            output_file = output_path / "course_dataset.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False, default=str)
                
            logger.info(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
            
        generation_time = time.time() - start_time
        
        # æ•°æ®è´¨é‡è¯„ä¼°
        logger.info("ğŸ” å¼€å§‹æ•°æ®è´¨é‡è¯„ä¼°...")
        quality_assessor = DataQualityAssessment()
        
        # æå–æ•°æ®ç”¨äºè´¨é‡è¯„ä¼°
        if isinstance(result, dict) and 'output_directory' in result:
            # å¤§è§„æ¨¡ç”Ÿæˆçš„ç»“æœ
            data_for_assessment = {
                'teachers': result.get('data_summary', {}).get('total_teachers', 0),
                'courses': result.get('data_summary', {}).get('total_courses', 0),
                'schedules': result.get('data_summary', {}).get('total_schedules', 0)
            }
            quality_report = None  # å¤§è§„æ¨¡æ•°æ®è·³è¿‡è¯¦ç»†è´¨é‡è¯„ä¼°
        else:
            # æ ‡å‡†ç”Ÿæˆçš„ç»“æœ
            data_for_assessment = {
                'teachers': result.get('teachers', []),
                'courses': result.get('courses', []),
                'schedules': result.get('schedules', []),
                'prerequisites': result.get('prerequisites', [])
            }
            quality_report = quality_assessor.assess_quality(data_for_assessment, sampling_rate=0.1)
            
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        final_report = {
            'generation_summary': {
                'total_time_seconds': generation_time,
                'generation_mode': generation_config.generation_mode.value,
                'processing_mode': batch_config.processing_mode.value,
                'constraint_compliance': {
                    'prerequisites_enabled': generation_config.enable_prerequisite_constraints,
                    'time_conflicts_enabled': generation_config.enable_time_conflict_detection,
                    'capacity_enabled': generation_config.enable_capacity_constraints,
                    'workload_enabled': generation_config.enable_teacher_workload_limits
                }
            },
            'data_statistics': result.get('data_summary', {}),
            'quality_assessment': quality_report.__dict__ if quality_report else None,
            'constraint_violations': result.get('constraint_violations', {}),
            'generation_config': generation_config.__dict__,
            'batch_config': batch_config.__dict__
        }
        
        # ä¿å­˜ç»¼åˆæŠ¥å‘Š
        report_file = Path(output_dir) / "generation_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False, default=str)
            
        # æ‰“å°æ€»ç»“
        logger.info("="*80)
        logger.info("âœ… æ•°æ®ç”Ÿæˆå®Œæˆ")
        logger.info("="*80)
        logger.info(f"â±ï¸ æ€»ç”¨æ—¶: {generation_time:.2f} ç§’")
        
        if quality_report:
            logger.info(f"ğŸ“ˆ æ•°æ®è´¨é‡å¾—åˆ†: {quality_report.overall_score:.3f}")
            logger.info(f"ğŸ”´ ä¸¥é‡é—®é¢˜: {quality_report.critical_issues} ä¸ª")
            logger.info(f"âš ï¸ æ€»é—®é¢˜æ•°: {quality_report.total_issues} ä¸ª")
            
        logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        if isinstance(result, dict):
            if 'data_summary' in result:
                stats = result['data_summary']
                for key, value in stats.items():
                    if isinstance(value, (int, float)):
                        logger.info(f"   {key}: {value:,}")
            else:
                logger.info(f"   æ•™å¸ˆ: {len(result.get('teachers', []))}")
                logger.info(f"   è¯¾ç¨‹: {len(result.get('courses', []))}")
                logger.info(f"   æ’è¯¾: {len(result.get('schedules', []))}")
                
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        logger.info(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        if quality_report and quality_report.recommendations:
            logger.info("ğŸ’¡ æ”¹è¿›å»ºè®®:")
            for rec in quality_report.recommendations:
                logger.info(f"   â€¢ {rec}")
                
        return final_report
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}")
        raise


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='çœŸå®è¯¾ç¨‹æ•°æ®ç”Ÿæˆå™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ç”Ÿæˆå°è§„æ¨¡æµ‹è¯•æ•°æ®
  python realistic_course_generator.py --students 1000 --teachers 50 --courses 200
  
  # ç”Ÿæˆä¸­ç­‰è§„æ¨¡æ•°æ®
  python realistic_course_generator.py --students 50000 --teachers 2500 --courses 5000
  
  # ç”Ÿæˆç™¾ä¸‡çº§æ•°æ®
  python realistic_course_generator.py --students 1000000 --teachers 50000 --courses 100000
  
  # è‡ªå®šä¹‰çº¦æŸè®¾ç½®
  python realistic_course_generator.py --students 10000 --realism-level 0.9 --constraint-strictness 0.8
        """
    )
    
    # æ•°æ®è§„æ¨¡å‚æ•°
    parser.add_argument('--students', type=int, default=10000,
                       help='ç›®æ ‡å­¦ç”Ÿæ•°é‡ (é»˜è®¤: 10000)')
    parser.add_argument('--teachers', type=int, default=500,
                       help='ç›®æ ‡æ•™å¸ˆæ•°é‡ (é»˜è®¤: 500)')
    parser.add_argument('--courses', type=int, default=1000,
                       help='ç›®æ ‡è¯¾ç¨‹æ•°é‡ (é»˜è®¤: 1000)')
    parser.add_argument('--schedules', type=int, default=50000,
                       help='ç›®æ ‡æ’è¯¾è®°å½•æ•°é‡ (é»˜è®¤: 50000)')
    parser.add_argument('--semesters', type=int, default=8,
                       help='å­¦æœŸæ•°é‡ (é»˜è®¤: 8)')
    
    # è´¨é‡å‚æ•°
    parser.add_argument('--realism-level', type=float, default=0.8,
                       help='çœŸå®æ€§è¦æ±‚ç­‰çº§ 0-1 (é»˜è®¤: 0.8)')
    parser.add_argument('--constraint-strictness', type=float, default=0.9,
                       help='çº¦æŸä¸¥æ ¼ç¨‹åº¦ 0-1 (é»˜è®¤: 0.9)')
    
    # çº¦æŸå¼€å…³
    parser.add_argument('--disable-prerequisites', action='store_true',
                       help='ç¦ç”¨å…ˆä¿®è¯¾ç¨‹çº¦æŸ')
    parser.add_argument('--disable-time-conflicts', action='store_true',
                       help='ç¦ç”¨æ—¶é—´å†²çªæ£€æµ‹')
    parser.add_argument('--disable-capacity', action='store_true',
                       help='ç¦ç”¨å®¹é‡çº¦æŸ')
    parser.add_argument('--disable-workload', action='store_true',
                       help='ç¦ç”¨æ•™å¸ˆå·¥ä½œè´Ÿè·é™åˆ¶')
    
    # æ€§èƒ½å‚æ•°
    parser.add_argument('--batch-size', type=int, default=2000,
                       help='æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 2000)')
    parser.add_argument('--max-memory', type=int, default=4096,
                       help='æœ€å¤§å†…å­˜é™åˆ¶MB (é»˜è®¤: 4096)')
    parser.add_argument('--memory-threshold', type=float, default=0.8,
                       help='å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼ (é»˜è®¤: 0.8)')
    parser.add_argument('--workers', type=int, default=4,
                       help='å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•° (é»˜è®¤: 4)')
    parser.add_argument('--gc-frequency', type=int, default=5,
                       help='åƒåœ¾å›æ”¶é¢‘ç‡ (é»˜è®¤: 5)')
    parser.add_argument('--checkpoint-interval', type=int, default=10000,
                       help='æ£€æŸ¥ç‚¹ä¿å­˜é—´éš” (é»˜è®¤: 10000)')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--output', '-o', default='course_data_output',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: course_data_output)')
    parser.add_argument('--log-level', default='INFO',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       help='æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)')
    parser.add_argument('--disable-compression', action='store_true',
                       help='ç¦ç”¨å‹ç¼©')
    parser.add_argument('--auto-resume', action='store_true',
                       help='è‡ªåŠ¨ä»æ£€æŸ¥ç‚¹æ¢å¤')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.log_level)
    
    try:
        # åˆ›å»ºé…ç½®
        generation_config = create_generation_config(args)
        batch_config = create_batch_config(args)
        
        # ç”Ÿæˆæ•°æ®
        result = generate_realistic_course_data(
            generation_config=generation_config,
            batch_config=batch_config,
            output_dir=args.output,
            logger=logger
        )
        
        logger.info("ğŸ‰ ç¨‹åºæ‰§è¡ŒæˆåŠŸå®Œæˆï¼")
        
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()