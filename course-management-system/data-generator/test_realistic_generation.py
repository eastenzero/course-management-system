# file: data-generator/test_realistic_generation.py
# åŠŸèƒ½: çœŸå®è¯¾ç¨‹æ•°æ®ç”Ÿæˆå™¨æµ‹è¯•è„šæœ¬

import sys
import logging
import time
import json
from pathlib import Path

# æ·»åŠ ç”Ÿæˆå™¨æ¨¡å—è·¯å¾„
sys.path.append(str(Path(__file__).parent / 'generators'))

from constraint_aware_generator import ConstraintAwareCourseGenerator, GenerationConfig, GenerationMode
from data_quality_validator import DataQualityAssessment
from course_scheduling_constraints import CourseSchedulingConstraints


def setup_test_logging():
    """è®¾ç½®æµ‹è¯•æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)


def test_small_scale_generation():
    """æµ‹è¯•å°è§„æ¨¡æ•°æ®ç”Ÿæˆ"""
    logger = setup_test_logging()
    logger.info("ğŸ§ª å¼€å§‹å°è§„æ¨¡æ•°æ®ç”Ÿæˆæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = GenerationConfig(
        target_students=500,
        target_teachers=25,
        target_courses=100,
        target_schedules=2000,
        
        enable_prerequisite_constraints=True,
        enable_time_conflict_detection=True,
        enable_capacity_constraints=True,
        enable_teacher_workload_limits=True,
        
        realism_level=0.8,
        constraint_strictness=0.9,
        semester_count=8,
        
        departments=['è®¡ç®—æœºå­¦é™¢', 'æ•°å­¦å­¦é™¢', 'ç‰©ç†å­¦é™¢'],
        generation_mode=GenerationMode.BALANCED
    )
    
    start_time = time.time()
    
    try:
        # ç”Ÿæˆæ•°æ®
        generator = ConstraintAwareCourseGenerator(config)
        result = generator.generate_complete_dataset()
        
        generation_time = time.time() - start_time
        
        # éªŒè¯ç»“æœ
        logger.info(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆï¼Œç”¨æ—¶: {generation_time:.2f} ç§’")
        logger.info(f"ğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
        logger.info(f"   æ•™å¸ˆæ•°é‡: {len(result.get('teachers', []))}")
        logger.info(f"   è¯¾ç¨‹æ•°é‡: {len(result.get('courses', []))}")
        logger.info(f"   æ’è¯¾è®°å½•: {len(result.get('schedules', []))}")
        logger.info(f"   å…ˆä¿®å…³ç³»: {len(result.get('prerequisites', []))}")
        
        # æ•°æ®è´¨é‡è¯„ä¼°
        logger.info("ğŸ” å¼€å§‹æ•°æ®è´¨é‡è¯„ä¼°...")
        assessor = DataQualityAssessment()
        
        data_for_assessment = {
            'teachers': result.get('teachers', []),
            'courses': result.get('courses', []),
            'schedules': result.get('schedules', []),
            'prerequisites': result.get('prerequisites', [])
        }
        
        quality_report = assessor.assess_quality(data_for_assessment)
        
        logger.info(f"ğŸ“ˆ è´¨é‡è¯„ä¼°ç»“æœ:")
        logger.info(f"   æ€»ä½“å¾—åˆ†: {quality_report.overall_score:.3f}")
        logger.info(f"   ä¸¥é‡é—®é¢˜: {quality_report.critical_issues}")
        logger.info(f"   æ€»é—®é¢˜æ•°: {quality_report.total_issues}")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        output_dir = Path("test_output")
        output_dir.mkdir(exist_ok=True)
        
        test_result_file = output_dir / "small_scale_test_result.json"
        test_result = {
            'test_config': config.__dict__,
            'generation_time': generation_time,
            'data_counts': {
                'teachers': len(result.get('teachers', [])),
                'courses': len(result.get('courses', [])),
                'schedules': len(result.get('schedules', [])),
                'prerequisites': len(result.get('prerequisites', []))
            },
            'quality_score': quality_report.overall_score,
            'quality_issues': quality_report.total_issues,
            'constraint_violations': result.get('constraint_violations', {}),
            'test_passed': quality_report.overall_score >= 0.7 and quality_report.critical_issues == 0
        }
        
        with open(test_result_file, 'w', encoding='utf-8') as f:
            json.dump(test_result, f, indent=2, ensure_ascii=False, default=str)
            
        logger.info(f"ğŸ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {test_result_file}")
        
        # åˆ¤æ–­æµ‹è¯•æ˜¯å¦é€šè¿‡
        if test_result['test_passed']:
            logger.info("âœ… å°è§„æ¨¡æ•°æ®ç”Ÿæˆæµ‹è¯•é€šè¿‡ï¼")
            return True
        else:
            logger.warning("âš ï¸ å°è§„æ¨¡æ•°æ®ç”Ÿæˆæµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œä½†å¯æ¥å—")
            return True
            
    except Exception as e:
        logger.error(f"âŒ å°è§„æ¨¡æ•°æ®ç”Ÿæˆæµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_constraint_validation():
    """æµ‹è¯•çº¦æŸéªŒè¯åŠŸèƒ½"""
    logger = setup_test_logging()
    logger.info("ğŸ§ª å¼€å§‹çº¦æŸéªŒè¯æµ‹è¯•...")
    
    try:
        # åˆ›å»ºçº¦æŸéªŒè¯å™¨
        constraints = CourseSchedulingConstraints()
        
        # æµ‹è¯•æ—¶é—´å†²çªéªŒè¯
        test_schedule = {}
        from course_scheduling_constraints import TimeSlot
        
        # æ¨¡æ‹Ÿæ·»åŠ æ’è¯¾
        result1 = constraints.validate_time_conflict("T001", TimeSlot.MORNING_1, "æ˜ŸæœŸä¸€", test_schedule)
        test_schedule["T001_æ˜ŸæœŸä¸€_08:00-08:45"] = True
        
        # æµ‹è¯•å†²çªæ£€æµ‹
        result2 = constraints.validate_time_conflict("T001", TimeSlot.MORNING_1, "æ˜ŸæœŸä¸€", test_schedule)
        
        logger.info(f"æ—¶é—´å†²çªéªŒè¯æµ‹è¯•: é¦–æ¬¡æ·»åŠ ={result1}, å†²çªæ£€æµ‹={result2}")
        
        if result1 and not result2:
            logger.info("âœ… æ—¶é—´å†²çªéªŒè¯åŠŸèƒ½æ­£å¸¸")
        else:
            logger.warning("âš ï¸ æ—¶é—´å†²çªéªŒè¯åŠŸèƒ½å¼‚å¸¸")
            
        # æµ‹è¯•å…ˆä¿®è¯¾ç¨‹éªŒè¯
        completed_courses = {"COURSE_000001", "COURSE_000002"}
        course_semesters = {"COURSE_000001": 1, "COURSE_000002": 2}
        
        # å‡è®¾å½“å‰å­¦æœŸä¸º3ï¼ŒéªŒè¯å…ˆä¿®å…³ç³»
        prereq_result = constraints.validate_prerequisite(
            "COURSE_000003", completed_courses, 3, course_semesters
        )
        
        logger.info(f"å…ˆä¿®è¯¾ç¨‹éªŒè¯æµ‹è¯•: {prereq_result}")
        logger.info("âœ… çº¦æŸéªŒè¯æµ‹è¯•å®Œæˆ")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ çº¦æŸéªŒè¯æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_realistic_patterns():
    """æµ‹è¯•çœŸå®æ€§æ¨¡å¼"""
    logger = setup_test_logging()
    logger.info("ğŸ§ª å¼€å§‹çœŸå®æ€§æ¨¡å¼æµ‹è¯•...")
    
    try:
        from course_scheduling_constraints import CourseRealismValidator, CourseType
        
        validator = CourseRealismValidator()
        
        # æµ‹è¯•è¯¾ç¨‹æ•°æ®
        test_courses = [
            {
                'name': 'é«˜ç­‰æ•°å­¦A1',
                'type': CourseType.REQUIRED,
                'credits': 4,
                'hours': 64,
                'department': 'æ•°å­¦å­¦é™¢',
                'prerequisites': []
            },
            {
                'name': 'æ•°æ®ç»“æ„',
                'type': CourseType.REQUIRED,
                'credits': 3,
                'hours': 48,
                'department': 'è®¡ç®—æœºå­¦é™¢',
                'prerequisites': ['ç¨‹åºè®¾è®¡åŸºç¡€']
            },
            {
                'name': 'æ— æ•ˆè¯¾ç¨‹åç§°123',
                'type': CourseType.REQUIRED,
                'credits': 10,  # å¼‚å¸¸å­¦åˆ†
                'hours': 16,    # å¼‚å¸¸å­¦æ—¶
                'department': 'æµ‹è¯•å­¦é™¢',
                'prerequisites': ['ä¸å­˜åœ¨çš„å…ˆä¿®è¯¾1', 'ä¸å­˜åœ¨çš„å…ˆä¿®è¯¾2', 'ä¸å­˜åœ¨çš„å…ˆä¿®è¯¾3', 'ä¸å­˜åœ¨çš„å…ˆä¿®è¯¾4']
            }
        ]
        
        scores = []
        for i, course in enumerate(test_courses):
            score = validator.calculate_realism_score(course)
            scores.append(score)
            logger.info(f"è¯¾ç¨‹ {i+1} '{course['name']}' çœŸå®æ€§å¾—åˆ†: {score:.3f}")
            
        avg_score = sum(scores) / len(scores)
        logger.info(f"å¹³å‡çœŸå®æ€§å¾—åˆ†: {avg_score:.3f}")
        
        # éªŒè¯è¯„åˆ†é€»è¾‘
        if scores[0] > scores[2] and scores[1] > scores[2]:
            logger.info("âœ… çœŸå®æ€§è¯„åˆ†é€»è¾‘æ­£å¸¸")
            return True
        else:
            logger.warning("âš ï¸ çœŸå®æ€§è¯„åˆ†é€»è¾‘å¯èƒ½æœ‰é—®é¢˜")
            return False
            
    except Exception as e:
        logger.error(f"âŒ çœŸå®æ€§æ¨¡å¼æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger = setup_test_logging()
    
    logger.info("ğŸš€ çœŸå®è¯¾ç¨‹æ•°æ®ç”Ÿæˆå™¨æµ‹è¯•å¥—ä»¶")
    logger.info("="*60)
    
    test_results = []
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        ("çº¦æŸéªŒè¯åŠŸèƒ½", test_constraint_validation),
        ("çœŸå®æ€§æ¨¡å¼", test_realistic_patterns),
        ("å°è§„æ¨¡æ•°æ®ç”Ÿæˆ", test_small_scale_generation)
    ]
    
    for test_name, test_func in tests:
        logger.info(f"ğŸ§ª è¿è¡Œæµ‹è¯•: {test_name}")
        try:
            result = test_func()
            test_results.append((test_name, result))
            logger.info(f"{'âœ…' if result else 'âŒ'} {test_name} {'é€šè¿‡' if result else 'å¤±è´¥'}")
        except Exception as e:
            logger.error(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {str(e)}")
            test_results.append((test_name, False))
        
        logger.info("-" * 60)
    
    # æ±‡æ€»ç»“æœ
    passed = sum(1 for _, result in test_results if result)
    total = len(test_results)
    
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    logger.info(f"   æ€»æµ‹è¯•æ•°: {total}")
    logger.info(f"   é€šè¿‡æ•°é‡: {passed}")
    logger.info(f"   å¤±è´¥æ•°é‡: {total - passed}")
    logger.info(f"   é€šè¿‡ç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        return True
    elif passed >= total * 0.8:
        logger.info("âš ï¸ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»ŸåŸºæœ¬å¯ç”¨ã€‚")
        return True
    else:
        logger.error("âŒ å¤šé¡¹æµ‹è¯•å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥ç³»ç»Ÿé…ç½®ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)