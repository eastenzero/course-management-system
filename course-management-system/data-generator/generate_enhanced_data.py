#!/usr/bin/env python3
"""
ä½¿ç”¨ä¿®æ­£çš„main.pyè„šæœ¬ç”Ÿæˆæ›´å¤§è§„æ¨¡çš„æ•°æ®
"""

import argparse
import sys
import time
from typing import Dict, Any, List
from datetime import datetime
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from config import DATA_SCALE_CONFIG, GenerationConfig
from generators import (
    DepartmentGenerator,
    UserGenerator,
    CourseGenerator,
    FacilityGenerator,
    ComplexScenarioGenerator,
    DataExporter
)

# å®šä¹‰æ‰©å¤§çš„æ•°æ®è§„æ¨¡é…ç½®
ENHANCED_DATA_SCALE_CONFIG = {
    'small': {
        'departments': 5,
        'students': 1000,
        'teachers': 50,
        'courses': 100,
        'classrooms': 20,
    },
    'medium': {
        'departments': 10,
        'students': 5000,
        'teachers': 200,
        'courses': 500,
        'classrooms': 50,
    },
    'large': {
        'departments': 15,
        'students': 25000,     # ä»10000æ‰©å¤§åˆ°25000
        'teachers': 1200,      # ä»500æ‰©å¤§åˆ°1200
        'courses': 3000,       # ä»1000æ‰©å¤§åˆ°3000
        'classrooms': 150,     # ä»80æ‰©å¤§åˆ°150
    },
    'huge': {
        'departments': 20,
        'students': 50000,     # 50000å­¦ç”Ÿ
        'teachers': 2500,      # 2500æ•™å¸ˆ
        'courses': 6000,       # 6000è¯¾ç¨‹
        'classrooms': 300,     # 300æ•™å®¤
    }
}

def generate_enhanced_dataset(scale: str = 'large', 
                            output_formats: List[str] = None,
                            output_dir: str = 'enhanced_output',
                            validate_data: bool = True,
                            include_conflicts: bool = True) -> Dict[str, Any]:
    """ç”Ÿæˆå¢å¼ºè§„æ¨¡çš„æµ‹è¯•æ•°æ®é›†"""
    if output_formats is None:
        output_formats = ['json', 'sql']
    
    # ä½¿ç”¨å¢å¼ºçš„æ•°æ®è§„æ¨¡é…ç½®
    config = ENHANCED_DATA_SCALE_CONFIG.get(scale, ENHANCED_DATA_SCALE_CONFIG['large'])
    
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {scale} è§„æ¨¡å¢å¼ºæ•°æ®...")
    print(f"ğŸ“Š å¢å¼ºæ•°æ®è§„æ¨¡é…ç½®:")
    for key, value in config.items():
        print(f"   {key}: {value:,}")
    print("-" * 80)
    
    start_time = time.time()
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    print("ğŸ”§ åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨...")
    dept_gen = DepartmentGenerator()
    user_gen = UserGenerator()
    course_gen = CourseGenerator()
    facility_gen = FacilityGenerator()
    scenario_gen = ComplexScenarioGenerator()
    exporter = DataExporter(output_dir)
    
    # ç”ŸæˆåŸºç¡€æ•°æ®
    print("\nğŸ“š ç”Ÿæˆé™¢ç³»ä¸“ä¸šæ•°æ®...")
    departments = dept_gen.generate_departments(config['departments'])
    majors = dept_gen.generate_majors(departments)
    print(f"   âœ… ç”Ÿæˆ {len(departments)} ä¸ªé™¢ç³»ï¼Œ{len(majors)} ä¸ªä¸“ä¸š")
    
    print("\nğŸ‘¥ ç”Ÿæˆç”¨æˆ·æ•°æ®...")
    students = user_gen.generate_students(config['students'], majors)
    teachers = user_gen.generate_teachers(config['teachers'], departments)
    print(f"   âœ… ç”Ÿæˆ {len(students):,} åå­¦ç”Ÿï¼Œ{len(teachers):,} åæ•™å¸ˆ")
    
    print("\nğŸ“– ç”Ÿæˆè¯¾ç¨‹æ•°æ®...")
    courses = course_gen.generate_courses(config['courses'], departments, teachers)
    print(f"   âœ… ç”Ÿæˆ {len(courses):,} é—¨è¯¾ç¨‹")
    
    print("\nğŸ¢ ç”Ÿæˆè®¾æ–½æ•°æ®...")
    classrooms = facility_gen.generate_classrooms(config['classrooms'])
    time_slots = facility_gen.generate_time_slots()
    print(f"   âœ… ç”Ÿæˆ {len(classrooms)} é—´æ•™å®¤ï¼Œ{len(time_slots)} ä¸ªæ—¶é—´æ®µ")
    
    print("\nğŸ¯ ç”Ÿæˆå¤æ‚åœºæ™¯æ•°æ®...")
    
    # åˆ†æ‰¹ç”Ÿæˆé€‰è¯¾è®°å½•ä»¥é¿å…å†…å­˜é—®é¢˜
    print("   ğŸ“ åˆ†æ‰¹ç”Ÿæˆé€‰è¯¾è®°å½•...")
    batch_size = 5000
    student_batches = [students[i:i+batch_size] for i in range(0, len(students), batch_size)]
    enrollments = []
    
    for i, student_batch in enumerate(student_batches):
        print(f"      æ‰¹æ¬¡ {i+1}/{len(student_batches)}: {len(student_batch)} åå­¦ç”Ÿ")
        batch_enrollments = scenario_gen.generate_enrollment_data(student_batch, courses)
        enrollments.extend(batch_enrollments)
    
    teacher_preferences = scenario_gen.generate_teacher_preferences(teachers, time_slots)
    print(f"   âœ… ç”Ÿæˆ {len(enrollments):,} æ¡é€‰è¯¾è®°å½•ï¼Œ{len(teacher_preferences):,} æ¡æ•™å¸ˆåå¥½")
    
    conflicts = []
    constraints = []
    if include_conflicts:
        print("   ğŸ” ç”Ÿæˆå†²çªåœºæ™¯å’Œçº¦æŸæ¡ä»¶...")
        conflicts = scenario_gen.generate_conflict_scenarios(courses, teachers, classrooms, students[:1000])  # é™åˆ¶å­¦ç”Ÿæ•°é‡é¿å…æ€§èƒ½é—®é¢˜
        constraints = scenario_gen.generate_scheduling_constraints(courses, teachers, classrooms)
        print(f"   âœ… ç”Ÿæˆ {len(conflicts)} ä¸ªå†²çªåœºæ™¯ï¼Œ{len(constraints)} ä¸ªçº¦æŸæ¡ä»¶")
    
    # ç»„è£…å®Œæ•´æ•°æ®é›†
    dataset = {
        'departments': departments,
        'majors': majors,
        'students': students,
        'teachers': teachers,
        'courses': courses,
        'classrooms': classrooms,
        'time_slots': time_slots,
        'enrollments': enrollments,
        'teacher_preferences': teacher_preferences,
        'conflicts': conflicts,
        'constraints': constraints,
    }

    # è®¡ç®—æ€»è®°å½•æ•°
    total_records = sum(len(v) if isinstance(v, list) else 0 for v in dataset.values() if v)

    generation_time = time.time() - start_time
    
    # æ·»åŠ å…ƒæ•°æ®
    dataset['metadata'] = {
        'scale': scale,
        'generated_at': datetime.now().isoformat(),
        'generator_version': '2.0.0',  # å¢å¼ºç‰ˆæœ¬
        'config': config,
        'total_records': total_records,
        'generation_time_seconds': round(generation_time, 2),
        'validation_passed': False,  # å°†åœ¨éªŒè¯åæ›´æ–°
        'output_formats': output_formats,
        'include_conflicts': include_conflicts
    }
    
    print(f"\nâœ¨ æ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print(f"   ğŸ“Š æ€»è®¡ {total_records:,} æ¡è®°å½•")
    print(f"   â±ï¸  è€—æ—¶ {generation_time:.2f} ç§’")
    print(f"   ğŸš€ ç”Ÿæˆé€Ÿåº¦ {total_records/generation_time:.0f} æ¡/ç§’")
    
    # æ•°æ®éªŒè¯
    validation_errors = {}
    if validate_data:
        print("\nğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")
        validation_start = time.time()
        validation_errors = exporter.validate_data_integrity(dataset)
        validation_time = time.time() - validation_start
        
        if validation_errors and any(validation_errors.values()):
            print(f"   âš ï¸  å‘ç° {sum(len(errors) for errors in validation_errors.values())} ä¸ªé—®é¢˜")
            for table, errors in validation_errors.items():
                if errors:
                    print(f"      - {table}: {len(errors)} ä¸ªé—®é¢˜")
            dataset['metadata']['validation_passed'] = False
        else:
            print(f"   âœ… æ•°æ®éªŒè¯é€šè¿‡ (è€—æ—¶ {validation_time:.2f} ç§’)")
            dataset['metadata']['validation_passed'] = True
    
    # å¯¼å‡ºæ•°æ®
    if output_formats:
        print(f"\nğŸ’¾ å¯¼å‡ºæ•°æ® (æ ¼å¼: {', '.join(output_formats)})...")
        export_start = time.time()
        
        exported_files = []
        if 'json' in output_formats:
            json_file = exporter.export_to_json(dataset)
            exported_files.append(json_file)
        
        if 'sql' in output_formats:
            sql_file = exporter.export_to_sql(dataset)
            exported_files.append(sql_file)
        
        # ç”Ÿæˆæ•°æ®æŠ¥å‘Š
        report_file = exporter.generate_data_report(dataset, validation_errors)
        exported_files.append(report_file)
        
        export_time = time.time() - export_start
        print(f"   âœ… å¯¼å‡ºå®Œæˆ (è€—æ—¶ {export_time:.2f} ç§’)")
        print(f"   ğŸ“ æ–‡ä»¶åˆ—è¡¨:")
        for file_path in exported_files:
            print(f"      - {file_path}")
    
    total_time = time.time() - start_time
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼æ€»è€—æ—¶ {total_time:.2f} ç§’")
    print("-" * 80)
    
    return dataset

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¢å¼ºè§„æ¨¡æ•°æ®ç”Ÿæˆ")
    print("="*80)
    
    # ç”Ÿæˆhugeè§„æ¨¡æ•°æ®ï¼ˆçº¦20-25ä¸‡æ¡è®°å½•ï¼‰
    try:
        dataset = generate_enhanced_dataset(
            scale='huge',
            output_formats=['json', 'sql'],
            output_dir='enhanced_huge_output',
            validate_data=True,
            include_conflicts=True
        )
        
        print("âœ… æ•°æ®ç”Ÿæˆä»»åŠ¡å®Œæˆï¼")
        metadata = dataset.get('metadata', {})
        print(f"ğŸ“Š æ€»è®°å½•æ•°: {metadata.get('total_records', 0):,}")
        print(f"â±ï¸ æ€»è€—æ—¶: {metadata.get('generation_time_seconds', 0):.2f} ç§’")
        print(f"âœ… éªŒè¯çŠ¶æ€: {metadata.get('validation_passed', False)}")
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("ğŸ‰ å¢å¼ºè§„æ¨¡æ•°æ®ç”ŸæˆæˆåŠŸå®Œæˆ")
    else:
        print("âŒ æ•°æ®ç”Ÿæˆä»»åŠ¡å¤±è´¥")
        sys.exit(1)