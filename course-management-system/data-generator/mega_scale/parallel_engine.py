# file: data-generator/mega_scale/parallel_engine.py
# åŠŸèƒ½: å¹¶è¡Œè®¡ç®—å¼•æ“å’Œä»»åŠ¡åˆ†é…ç³»ç»Ÿ

import multiprocessing as mp
import threading
import time
import queue
import psutil
from typing import Any, Dict, List, Optional, Callable, Tuple, Union
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed, Future
from dataclasses import dataclass, field
from pathlib import Path
import pickle
import json


@dataclass
class TaskConfig:
    """ä»»åŠ¡é…ç½®"""
    task_id: str
    task_type: str                    # ä»»åŠ¡ç±»å‹
    priority: int = 5                 # ä¼˜å…ˆçº§ (1-10, 1æœ€é«˜)
    estimated_duration: float = 60.0  # é¢„ä¼°è€—æ—¶(ç§’)
    memory_requirement_mb: int = 100   # å†…å­˜éœ€æ±‚(MB)
    cpu_intensive: bool = True         # æ˜¯å¦CPUå¯†é›†å‹
    dependencies: List[str] = field(default_factory=list)  # ä¾èµ–ä»»åŠ¡ID


@dataclass
class WorkerConfig:
    """å·¥ä½œè¿›ç¨‹é…ç½®"""
    worker_id: str
    process_type: str = "process"     # process æˆ– thread
    max_tasks: int = 100             # æœ€å¤§ä»»åŠ¡æ•°
    max_memory_mb: int = 512         # æœ€å¤§å†…å­˜é™åˆ¶
    timeout_seconds: int = 3600      # è¶…æ—¶æ—¶é—´


@dataclass
class TaskResult:
    """ä»»åŠ¡ç»“æœ"""
    task_id: str
    success: bool
    result: Any = None
    error: str = ""
    processing_time: float = 0.0
    memory_used_mb: float = 0.0
    worker_id: str = ""


class LoadBalancer:
    """è´Ÿè½½å‡è¡¡å™¨"""
    
    def __init__(self, workers: List[WorkerConfig]):
        self.workers = {w.worker_id: w for w in workers}
        self.worker_loads: Dict[str, float] = {w.worker_id: 0.0 for w in workers}
        self.worker_task_counts: Dict[str, int] = {w.worker_id: 0 for w in workers}
        self.lock = threading.Lock()
    
    def select_worker(self, task: TaskConfig) -> Optional[str]:
        """é€‰æ‹©æœ€åˆé€‚çš„å·¥ä½œè¿›ç¨‹"""
        with self.lock:
            # è¿‡æ»¤å¯ç”¨çš„å·¥ä½œè¿›ç¨‹
            available_workers = []
            
            for worker_id, worker_config in self.workers.items():
                # æ£€æŸ¥å†…å­˜è¦æ±‚
                if task.memory_requirement_mb <= worker_config.max_memory_mb:
                    # æ£€æŸ¥ä»»åŠ¡æ•°é™åˆ¶
                    if self.worker_task_counts[worker_id] < worker_config.max_tasks:
                        load = self.worker_loads[worker_id]
                        task_count = self.worker_task_counts[worker_id]
                        
                        # è®¡ç®—è´Ÿè½½åˆ†æ•° (è¶Šå°è¶Šå¥½)
                        load_score = load + (task_count * 0.1)
                        available_workers.append((worker_id, load_score))
            
            if not available_workers:
                return None
            
            # é€‰æ‹©è´Ÿè½½æœ€å°çš„å·¥ä½œè¿›ç¨‹
            selected_worker = min(available_workers, key=lambda x: x[1])[0]
            
            # æ›´æ–°è´Ÿè½½ä¿¡æ¯
            self.worker_loads[selected_worker] += task.estimated_duration
            self.worker_task_counts[selected_worker] += 1
            
            return selected_worker
    
    def update_worker_completion(self, worker_id: str, actual_duration: float):
        """æ›´æ–°å·¥ä½œè¿›ç¨‹å®Œæˆæƒ…å†µ"""
        with self.lock:
            if worker_id in self.worker_loads:
                self.worker_loads[worker_id] = max(0, 
                    self.worker_loads[worker_id] - actual_duration)
                self.worker_task_counts[worker_id] = max(0,
                    self.worker_task_counts[worker_id] - 1)
    
    def get_load_summary(self) -> Dict[str, Any]:
        """è·å–è´Ÿè½½æ‘˜è¦"""
        with self.lock:
            return {
                'workers': dict(self.workers),
                'loads': dict(self.worker_loads),
                'task_counts': dict(self.worker_task_counts),
                'total_load': sum(self.worker_loads.values()),
                'total_tasks': sum(self.worker_task_counts.values())
            }


class TaskQueue:
    """ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†å™¨"""
    
    def __init__(self):
        self.pending_tasks: Dict[int, List[TaskConfig]] = {}  # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        self.running_tasks: Dict[str, TaskConfig] = {}
        self.completed_tasks: Dict[str, TaskResult] = {}
        self.failed_tasks: Dict[str, TaskResult] = {}
        self.task_dependencies: Dict[str, List[str]] = {}
        self.lock = threading.Lock()
    
    def add_task(self, task: TaskConfig):
        """æ·»åŠ ä»»åŠ¡"""
        with self.lock:
            if task.priority not in self.pending_tasks:
                self.pending_tasks[task.priority] = []
            
            self.pending_tasks[task.priority].append(task)
            
            # è®°å½•ä¾èµ–å…³ç³»
            if task.dependencies:
                self.task_dependencies[task.task_id] = task.dependencies
    
    def get_next_task(self) -> Optional[TaskConfig]:
        """è·å–ä¸‹ä¸€ä¸ªå¯æ‰§è¡Œä»»åŠ¡"""
        with self.lock:
            # æŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½éå†
            for priority in sorted(self.pending_tasks.keys()):
                tasks = self.pending_tasks[priority]
                
                for i, task in enumerate(tasks):
                    # æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³
                    if self._are_dependencies_satisfied(task.task_id):
                        # ç§»é™¤å¹¶è¿”å›ä»»åŠ¡
                        tasks.pop(i)
                        if not tasks:
                            del self.pending_tasks[priority]
                        
                        self.running_tasks[task.task_id] = task
                        return task
            
            return None
    
    def _are_dependencies_satisfied(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡ä¾èµ–æ˜¯å¦æ»¡è¶³"""
        dependencies = self.task_dependencies.get(task_id, [])
        
        for dep_id in dependencies:
            if dep_id not in self.completed_tasks:
                return False
        
        return True
    
    def complete_task(self, result: TaskResult):
        """å®Œæˆä»»åŠ¡"""
        with self.lock:
            task_id = result.task_id
            
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]
            
            if result.success:
                self.completed_tasks[task_id] = result
            else:
                self.failed_tasks[task_id] = result
    
    def get_status(self) -> Dict[str, int]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        with self.lock:
            pending_count = sum(len(tasks) for tasks in self.pending_tasks.values())
            
            return {
                'pending': pending_count,
                'running': len(self.running_tasks),
                'completed': len(self.completed_tasks),
                'failed': len(self.failed_tasks),
                'total': pending_count + len(self.running_tasks) + 
                        len(self.completed_tasks) + len(self.failed_tasks)
            }


class WorkerProcess:
    """å·¥ä½œè¿›ç¨‹"""
    
    def __init__(self, config: WorkerConfig):
        self.config = config
        self.process = psutil.Process()
        self.current_task: Optional[TaskConfig] = None
        self.start_time: Optional[float] = None
        self.task_count = 0
        self.total_processing_time = 0.0
    
    @staticmethod
    def execute_task(task_config: TaskConfig, task_func: Callable, 
                    task_args: Tuple, task_kwargs: Dict) -> TaskResult:
        """æ‰§è¡Œä»»åŠ¡ï¼ˆé™æ€æ–¹æ³•ï¼Œç”¨äºå¤šè¿›ç¨‹ï¼‰"""
        start_time = time.time()
        worker_id = mp.current_process().name
        
        try:
            # æ‰§è¡Œä»»åŠ¡
            result = task_func(*task_args, **task_kwargs)
            
            processing_time = time.time() - start_time
            
            # è·å–å†…å­˜ä½¿ç”¨é‡
            process = psutil.Process()
            memory_used_mb = process.memory_info().rss / 1024 / 1024
            
            return TaskResult(
                task_id=task_config.task_id,
                success=True,
                result=result,
                processing_time=processing_time,
                memory_used_mb=memory_used_mb,
                worker_id=worker_id
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            
            return TaskResult(
                task_id=task_config.task_id,
                success=False,
                error=str(e),
                processing_time=processing_time,
                worker_id=worker_id
            )


class ParallelComputingEngine:
    """å¹¶è¡Œè®¡ç®—å¼•æ“"""
    
    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or min(32, (psutil.cpu_count() or 1) + 4)
        self.task_queue = TaskQueue()
        self.load_balancer: Optional[LoadBalancer] = None
        self.process_executor: Optional[ProcessPoolExecutor] = None
        self.thread_executor: Optional[ThreadPoolExecutor] = None
        
        # ä»»åŠ¡æ³¨å†Œè¡¨
        self.task_functions: Dict[str, Callable] = {}
        self.task_args: Dict[str, Tuple] = {}
        self.task_kwargs: Dict[str, Dict] = {}
        
        # è¿è¡ŒçŠ¶æ€
        self.running = False
        self.coordinator_thread: Optional[threading.Thread] = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.start_time: Optional[float] = None
        self.total_tasks_processed = 0
        self.total_processing_time = 0.0
    
    def register_task_function(self, task_type: str, func: Callable):
        """æ³¨å†Œä»»åŠ¡å¤„ç†å‡½æ•°"""
        self.task_functions[task_type] = func
    
    def initialize_workers(self, process_workers: int = None, thread_workers: int = None):
        """åˆå§‹åŒ–å·¥ä½œè¿›ç¨‹å’Œçº¿ç¨‹"""
        if process_workers is None:
            process_workers = max(1, self.max_workers // 2)
        if thread_workers is None:
            thread_workers = max(1, self.max_workers - process_workers)
        
        # åˆ›å»ºå·¥ä½œè¿›ç¨‹é…ç½®
        worker_configs = []
        
        for i in range(process_workers):
            config = WorkerConfig(
                worker_id=f"process_{i}",
                process_type="process",
                max_memory_mb=512
            )
            worker_configs.append(config)
        
        for i in range(thread_workers):
            config = WorkerConfig(
                worker_id=f"thread_{i}",
                process_type="thread",
                max_memory_mb=256
            )
            worker_configs.append(config)
        
        # åˆå§‹åŒ–è´Ÿè½½å‡è¡¡å™¨
        self.load_balancer = LoadBalancer(worker_configs)
        
        # åˆ›å»ºæ‰§è¡Œå™¨
        self.process_executor = ProcessPoolExecutor(max_workers=process_workers)
        self.thread_executor = ThreadPoolExecutor(max_workers=thread_workers)
        
        print(f"ğŸš€ åˆå§‹åŒ–å¹¶è¡Œå¼•æ“: {process_workers}è¿›ç¨‹ + {thread_workers}çº¿ç¨‹")
    
    def submit_task(self, task_config: TaskConfig, func: Callable, 
                   *args, **kwargs) -> str:
        """æäº¤ä»»åŠ¡"""
        # æ³¨å†Œä»»åŠ¡å‡½æ•°å’Œå‚æ•°
        self.task_functions[task_config.task_id] = func
        self.task_args[task_config.task_id] = args
        self.task_kwargs[task_config.task_id] = kwargs
        
        # æ·»åŠ åˆ°ä»»åŠ¡é˜Ÿåˆ—
        self.task_queue.add_task(task_config)
        
        return task_config.task_id
    
    def submit_batch_tasks(self, tasks: List[Tuple[TaskConfig, Callable, Tuple, Dict]]) -> List[str]:
        """æ‰¹é‡æäº¤ä»»åŠ¡"""
        task_ids = []
        
        for task_config, func, args, kwargs in tasks:
            task_id = self.submit_task(task_config, func, *args, **kwargs)
            task_ids.append(task_id)
        
        return task_ids
    
    def start_processing(self):
        """å¼€å§‹å¤„ç†ä»»åŠ¡"""
        if self.running:
            return
        
        self.running = True
        self.start_time = time.time()
        
        # å¯åŠ¨ä»»åŠ¡åè°ƒçº¿ç¨‹
        self.coordinator_thread = threading.Thread(target=self._task_coordinator, daemon=True)
        self.coordinator_thread.start()
        
        print("ğŸ“Š å¹¶è¡Œå¼•æ“å¼€å§‹å¤„ç†ä»»åŠ¡...")
    
    def _task_coordinator(self):
        """ä»»åŠ¡åè°ƒå™¨ï¼ˆä¸»æ§åˆ¶å¾ªç¯ï¼‰"""
        futures_to_tasks: Dict[Future, TaskConfig] = {}
        
        while self.running:
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯æ‰§è¡Œçš„ä»»åŠ¡
                task = self.task_queue.get_next_task()
                
                if task:
                    # é€‰æ‹©å·¥ä½œè¿›ç¨‹
                    worker_id = self.load_balancer.select_worker(task)
                    
                    if worker_id:
                        # æäº¤ä»»åŠ¡åˆ°ç›¸åº”çš„æ‰§è¡Œå™¨
                        if worker_id.startswith("process_"):
                            future = self.process_executor.submit(
                                WorkerProcess.execute_task,
                                task,
                                self.task_functions[task.task_id],
                                self.task_args[task.task_id],
                                self.task_kwargs[task.task_id]
                            )
                        else:  # thread worker
                            future = self.thread_executor.submit(
                                WorkerProcess.execute_task,
                                task,
                                self.task_functions[task.task_id],
                                self.task_args[task.task_id],
                                self.task_kwargs[task.task_id]
                            )
                        
                        futures_to_tasks[future] = task
                
                # æ£€æŸ¥å®Œæˆçš„ä»»åŠ¡
                completed_futures = []
                for future in list(futures_to_tasks.keys()):
                    if future.done():
                        completed_futures.append(future)
                
                for future in completed_futures:
                    task = futures_to_tasks.pop(future)
                    
                    try:
                        result = future.result()
                        
                        # æ›´æ–°è´Ÿè½½å‡è¡¡å™¨
                        self.load_balancer.update_worker_completion(
                            result.worker_id, result.processing_time
                        )
                        
                        # å®Œæˆä»»åŠ¡
                        self.task_queue.complete_task(result)
                        
                        # æ›´æ–°ç»Ÿè®¡
                        self.total_tasks_processed += 1
                        self.total_processing_time += result.processing_time
                        
                        # æ¸…ç†ä»»åŠ¡æ•°æ®
                        self._cleanup_task_data(task.task_id)
                        
                    except Exception as e:
                        print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
                        
                        # åˆ›å»ºå¤±è´¥ç»“æœ
                        failed_result = TaskResult(
                            task_id=task.task_id,
                            success=False,
                            error=str(e)
                        )
                        self.task_queue.complete_task(failed_result)
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆ
                status = self.task_queue.get_status()
                if status['pending'] == 0 and status['running'] == 0:
                    # æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œä½†ä¿æŒè¿è¡ŒçŠ¶æ€ç­‰å¾…æ–°ä»»åŠ¡
                    time.sleep(0.1)
                else:
                    time.sleep(0.01)  # çŸ­æš‚ä¼‘çœ 
                    
            except Exception as e:
                print(f"ä»»åŠ¡åè°ƒå™¨å¼‚å¸¸: {e}")
                time.sleep(1)
    
    def _cleanup_task_data(self, task_id: str):
        """æ¸…ç†ä»»åŠ¡æ•°æ®"""
        if task_id in self.task_functions:
            del self.task_functions[task_id]
        if task_id in self.task_args:
            del self.task_args[task_id]
        if task_id in self.task_kwargs:
            del self.task_kwargs[task_id]
    
    def wait_for_completion(self, timeout: float = None) -> bool:
        """ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ"""
        start_wait = time.time()
        
        while True:
            status = self.task_queue.get_status()
            
            if status['pending'] == 0 and status['running'] == 0:
                return True
            
            if timeout and (time.time() - start_wait) > timeout:
                return False
            
            time.sleep(1)
    
    def get_results(self) -> Dict[str, TaskResult]:
        """è·å–æ‰€æœ‰å®Œæˆçš„ä»»åŠ¡ç»“æœ"""
        return dict(self.task_queue.completed_tasks)
    
    def get_failed_results(self) -> Dict[str, TaskResult]:
        """è·å–æ‰€æœ‰å¤±è´¥çš„ä»»åŠ¡ç»“æœ"""
        return dict(self.task_queue.failed_tasks)
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        elapsed_time = time.time() - (self.start_time or time.time())
        
        stats = {
            'total_tasks_processed': self.total_tasks_processed,
            'total_processing_time': self.total_processing_time,
            'elapsed_time': elapsed_time,
            'tasks_per_second': self.total_tasks_processed / max(elapsed_time, 1),
            'avg_task_time': self.total_processing_time / max(self.total_tasks_processed, 1),
            'parallel_efficiency': (self.total_processing_time / (elapsed_time * self.max_workers)) * 100 if elapsed_time > 0 else 0,
            'queue_status': self.task_queue.get_status()
        }
        
        if self.load_balancer:
            stats['load_balancer'] = self.load_balancer.get_load_summary()
        
        return stats
    
    def stop(self):
        """åœæ­¢å¤„ç†"""
        self.running = False
        
        # ç­‰å¾…åè°ƒçº¿ç¨‹ç»“æŸ
        if self.coordinator_thread and self.coordinator_thread.is_alive():
            self.coordinator_thread.join(timeout=5)
        
        # å…³é—­æ‰§è¡Œå™¨
        if self.process_executor:
            self.process_executor.shutdown(wait=True)
        if self.thread_executor:
            self.thread_executor.shutdown(wait=True)
        
        print("ğŸ›‘ å¹¶è¡Œå¼•æ“å·²åœæ­¢")


class ResultMerger:
    """ç»“æœåˆå¹¶å™¨"""
    
    def __init__(self):
        self.results: Dict[str, Any] = {}
        self.merge_strategies: Dict[str, Callable] = {}
        self.lock = threading.Lock()
    
    def register_merge_strategy(self, result_type: str, merge_func: Callable):
        """æ³¨å†Œåˆå¹¶ç­–ç•¥"""
        self.merge_strategies[result_type] = merge_func
    
    def add_result(self, result_type: str, task_id: str, data: Any):
        """æ·»åŠ ç»“æœ"""
        with self.lock:
            if result_type not in self.results:
                self.results[result_type] = {}
            
            self.results[result_type][task_id] = data
    
    def merge_results(self, result_type: str) -> Any:
        """åˆå¹¶æŒ‡å®šç±»å‹çš„ç»“æœ"""
        with self.lock:
            if result_type not in self.results:
                return None
            
            results_data = self.results[result_type]
            
            if result_type in self.merge_strategies:
                # ä½¿ç”¨è‡ªå®šä¹‰åˆå¹¶ç­–ç•¥
                return self.merge_strategies[result_type](results_data)
            else:
                # é»˜è®¤åˆå¹¶ç­–ç•¥ï¼šç®€å•åˆ—è¡¨åˆå¹¶
                return self._default_merge(results_data)
    
    def _default_merge(self, results_data: Dict[str, Any]) -> List[Any]:
        """é»˜è®¤åˆå¹¶ç­–ç•¥"""
        merged = []
        
        for task_id in sorted(results_data.keys()):
            data = results_data[task_id]
            
            if isinstance(data, list):
                merged.extend(data)
            else:
                merged.append(data)
        
        return merged
    
    def get_all_merged_results(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰åˆå¹¶åçš„ç»“æœ"""
        merged_results = {}
        
        for result_type in self.results.keys():
            merged_results[result_type] = self.merge_results(result_type)
        
        return merged_results