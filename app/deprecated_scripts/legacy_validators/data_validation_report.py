#!/usr/bin/env python
"""
æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥è„šæœ¬
éªŒè¯å½“å‰æ•°æ®åº“ä¸­çš„æ•°æ®çŠ¶æ€ï¼Œä¸ºç™¾ä¸‡çº§æ•°æ®è¿ç§»æä¾›åŸºç¡€æŠ¥å‘Š

åŠŸèƒ½ï¼š
1. ç»Ÿè®¡å½“å‰æ•°æ®åº“ä¸­çš„æ•°æ®é‡
2. åˆ†ææ•°æ®è´¨é‡å’Œå®Œæ•´æ€§
3. è¯†åˆ«æ±¡æŸ“æ•°æ®
4. ä¸ºè¿ç§»åˆ¶å®šç­–ç•¥å»ºè®®
"""

import sqlite3
import os
from datetime import datetime
from pathlib import Path

class DatabaseValidator:
    """æ•°æ®åº“éªŒè¯å™¨"""
    
    def __init__(self):
        self.db_path = self.find_database_file()
        self.stats = {}
        self.validation_results = {}
        
    def find_database_file(self):
        """æŸ¥æ‰¾æ•°æ®åº“æ–‡ä»¶"""
        possible_paths = [
            'course-management-system/backend/db.sqlite3',
            'backend/db.sqlite3',
            'db.sqlite3'
        ]
        
        for path in possible_paths:
            full_path = os.path.join(os.getcwd(), path)
            if os.path.exists(full_path):
                print(f"ğŸ“‚ æ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶: {full_path}")
                return full_path
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æŠ¥å‘Š
        print("âš ï¸ æœªæ‰¾åˆ°SQLiteæ•°æ®åº“æ–‡ä»¶")
        return None
    
    def analyze_current_data(self):
        """åˆ†æå½“å‰æ•°æ®çŠ¶æ€"""
        if not self.db_path:
            return self.create_file_based_analysis()
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = cursor.fetchall()
            
            self.stats = {'tables': {}}
            
            for (table_name,) in tables:
                if table_name.startswith('django_') or table_name == 'sqlite_sequence':
                    continue
                
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                    count = cursor.fetchone()[0]
                    self.stats['tables'][table_name] = count
                    print(f"   {table_name}: {count:,} æ¡è®°å½•")
                except Exception as e:
                    print(f"   âš ï¸ æ— æ³•æŸ¥è¯¢è¡¨ {table_name}: {e}")
            
            # ç‰¹æ®ŠæŸ¥è¯¢ï¼šç”¨æˆ·ç›¸å…³æ•°æ®
            try:
                cursor.execute("SELECT COUNT(*) FROM auth_user WHERE username LIKE 'million_%'")
                million_users = cursor.fetchone()[0]
                self.stats['million_users'] = million_users
                
                cursor.execute("SELECT COUNT(*) FROM auth_user WHERE user_type = 'student'")
                student_count = cursor.fetchone()[0]
                self.stats['student_users'] = student_count
                
                cursor.execute("SELECT COUNT(*) FROM auth_user WHERE user_type = 'teacher'")
                teacher_count = cursor.fetchone()[0]
                self.stats['teacher_users'] = teacher_count
                
            except Exception as e:
                print(f"   âš ï¸ æ— æ³•æŸ¥è¯¢ç”¨æˆ·æ•°æ®: {e}")
            
            conn.close()
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“åˆ†æå¤±è´¥: {e}")
            return self.create_file_based_analysis()
        
        return self.stats
    
    def create_file_based_analysis(self):
        """åŸºäºæ–‡ä»¶ç³»ç»Ÿçš„åˆ†æ"""
        print("ğŸ“ æ‰§è¡ŒåŸºäºæ–‡ä»¶ç³»ç»Ÿçš„æ•°æ®åˆ†æ...")
        
        # æ£€æŸ¥é¡¹ç›®ä¸­çš„è„šæœ¬æ–‡ä»¶
        scripts_analysis = {
            'professional_scripts_found': [],
            'data_generation_scripts': [],
            'million_data_scripts': []
        }
        
        project_root = os.getcwd()
        
        # æ‰«æPythonè„šæœ¬
        for root, dirs, files in os.walk(project_root):
            for file in files:
                if file.endswith('.py'):
                    file_path = os.path.join(root, file)
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç™¾ä¸‡çº§æ•°æ®ç”Ÿæˆè„šæœ¬
                    if 'million' in file.lower():
                        scripts_analysis['million_data_scripts'].append(file_path)
                    
                    if 'generate' in file.lower() and 'data' in file.lower():
                        scripts_analysis['data_generation_scripts'].append(file_path)
                    
                    # æ£€æŸ¥ä¸“ä¸šè„šæœ¬
                    if 'simplified' in file.lower() or 'professional' in file.lower():
                        scripts_analysis['professional_scripts_found'].append(file_path)
        
        return scripts_analysis
    
    def identify_pollution_patterns(self):
        """è¯†åˆ«æ•°æ®æ±¡æŸ“æ¨¡å¼"""
        pollution_patterns = {
            'username_patterns': [
                'million_', 'MILLION_', 'test_', 'student_', 'teacher_', 
                'user_', 'demo_', 'sample_', 'example_', 'dummy_'
            ],
            'course_patterns': [
                'MILLION_', 'TEST_', 'DEMO_', 'SAMPLE_', 'EXAMPLE_'
            ]
        }
        
        print("ğŸ” è¯†åˆ«çš„æ±¡æŸ“æ•°æ®æ¨¡å¼:")
        print("   ç”¨æˆ·åæ¨¡å¼:", ', '.join(pollution_patterns['username_patterns']))
        print("   è¯¾ç¨‹ä»£ç æ¨¡å¼:", ', '.join(pollution_patterns['course_patterns']))
        
        return pollution_patterns
    
    def validate_professional_script(self):
        """éªŒè¯ä¸“ä¸šç™¾ä¸‡çº§æ•°æ®ç”Ÿæˆè„šæœ¬"""
        script_path = 'course-management-system/generate_real_million_data_simplified.py'
        full_path = os.path.join(os.getcwd(), script_path)
        
        if os.path.exists(full_path):
            print(f"âœ… ä¸“ä¸šè„šæœ¬ç¡®è®¤å­˜åœ¨: {script_path}")
            
            # è¯»å–è„šæœ¬å†…å®¹ï¼Œåˆ†æå…³é”®ç‰¹æ€§
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                professional_features = {
                    'batch_processing': 'batch_size' in content,
                    'memory_optimization': 'gc.collect()' in content,
                    'chinese_names': 'generate_chinese_name' in content,
                    'password_optimization': 'make_password' in content,
                    'error_handling': 'try:' in content and 'except' in content,
                    'progress_monitoring': 'è¿›åº¦' in content or 'progress' in content.lower(),
                }
                
                print("ğŸ”§ ä¸“ä¸šè„šæœ¬ç‰¹æ€§åˆ†æ:")
                for feature, exists in professional_features.items():
                    status = "âœ…" if exists else "âŒ"
                    print(f"   {status} {feature}: {'æ˜¯' if exists else 'å¦'}")
                
                return {
                    'script_exists': True,
                    'script_path': full_path,
                    'professional_features': professional_features
                }
                
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–è„šæœ¬å†…å®¹: {e}")
                
        else:
            print(f"âŒ ä¸“ä¸šè„šæœ¬ä¸å­˜åœ¨: {script_path}")
            
        return {'script_exists': False}
    
    def calculate_migration_strategy(self):
        """è®¡ç®—è¿ç§»ç­–ç•¥"""
        current_total = sum(self.stats.get('tables', {}).values())
        million_target = 1000000
        
        strategy = {
            'current_total_records': current_total,
            'million_target': million_target,
            'needs_migration': current_total < million_target,
            'cleanup_required': self.stats.get('million_users', 0) > 0,
            'estimated_generation_time': '2-3å°æ—¶ï¼ˆåŸºäºä¸“ä¸šè„šæœ¬ï¼‰',
            'recommended_approach': 'professional_simplified_script'
        }
        
        if strategy['needs_migration']:
            shortage = million_target - current_total
            strategy['records_to_generate'] = shortage
            print(f"ğŸ“Š è¿ç§»ç­–ç•¥åˆ†æ:")
            print(f"   å½“å‰è®°å½•æ•°: {current_total:,}")
            print(f"   ç›®æ ‡è®°å½•æ•°: {million_target:,}")
            print(f"   éœ€è¦ç”Ÿæˆ: {shortage:,} æ¡è®°å½•")
            print(f"   æ¨èæ–¹å¼: ä½¿ç”¨ä¸“ä¸šè„šæœ¬ generate_real_million_data_simplified.py")
        else:
            print(f"âœ… å½“å‰æ•°æ®å·²è¾¾åˆ°ç™¾ä¸‡çº§æ ‡å‡†")
        
        return strategy
    
    def generate_validation_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆæ•°æ®éªŒè¯æŠ¥å‘Š")
        print("=" * 80)
        print(f"â° æŠ¥å‘Šæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
        # 1. æ•°æ®åˆ†æ
        print("\nğŸ” ç¬¬1éƒ¨åˆ†: æ•°æ®çŠ¶æ€åˆ†æ")
        current_data = self.analyze_current_data()
        
        # 2. æ±¡æŸ“è¯†åˆ«
        print("\nğŸ§¹ ç¬¬2éƒ¨åˆ†: æ±¡æŸ“æ•°æ®è¯†åˆ«")
        pollution_patterns = self.identify_pollution_patterns()
        
        # 3. ä¸“ä¸šè„šæœ¬éªŒè¯
        print("\nğŸ”§ ç¬¬3éƒ¨åˆ†: ä¸“ä¸šè„šæœ¬éªŒè¯")
        script_validation = self.validate_professional_script()
        
        # 4. è¿ç§»ç­–ç•¥
        print("\nğŸ“Š ç¬¬4éƒ¨åˆ†: è¿ç§»ç­–ç•¥è®¡ç®—")
        migration_strategy = self.calculate_migration_strategy()
        
        # 5. æ€»ç»“æŠ¥å‘Š
        self.validation_results = {
            'timestamp': datetime.now().isoformat(),
            'current_data': current_data,
            'pollution_patterns': pollution_patterns,
            'script_validation': script_validation,
            'migration_strategy': migration_strategy,
            'recommendations': self.generate_recommendations()
        }
        
        print("\n" + "=" * 80)
        print("ğŸ“‹ éªŒè¯æŠ¥å‘Šæ€»ç»“")
        print("=" * 80)
        
        return self.validation_results
    
    def generate_recommendations(self):
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        # åŸºäºä¸“ä¸šè„šæœ¬çš„å»ºè®®
        if self.validation_results.get('script_validation', {}).get('script_exists'):
            recommendations.append({
                'priority': 'HIGH',
                'category': 'Professional Script',
                'action': 'ä½¿ç”¨ä¸“ä¸šè„šæœ¬ generate_real_million_data_simplified.py',
                'reason': 'è¯¥è„šæœ¬ç»è¿‡ä¸“ä¸šä¼˜åŒ–ï¼Œå…·å¤‡å†…å­˜ç®¡ç†ã€æ‰¹å¤„ç†ã€çœŸå®æ•°æ®ç”Ÿæˆç­‰ç‰¹æ€§',
                'estimated_time': '2-3å°æ—¶'
            })
        
        # æ•°æ®æ¸…ç†å»ºè®®
        if self.stats.get('million_users', 0) > 0:
            recommendations.append({
                'priority': 'MEDIUM',
                'category': 'Data Cleanup',
                'action': 'æ¸…ç†ç°æœ‰million_å‰ç¼€çš„æµ‹è¯•æ•°æ®',
                'reason': 'é¿å…æ•°æ®æ±¡æŸ“ï¼Œç¡®ä¿æ–°ç”Ÿæˆæ•°æ®çš„è´¨é‡',
                'estimated_time': '30åˆ†é’Ÿ'
            })
        
        # ç¯å¢ƒå‡†å¤‡å»ºè®®
        recommendations.append({
            'priority': 'HIGH',
            'category': 'Environment Setup',
            'action': 'ç¡®ä¿Djangoç¯å¢ƒå’Œä¾èµ–åŒ…å®Œæ•´å®‰è£…',
            'reason': 'ä¸“ä¸šè„šæœ¬éœ€è¦å®Œæ•´çš„Djangoç¯å¢ƒæ”¯æŒ',
            'estimated_time': '1å°æ—¶'
        })
        
        print("ğŸ’¡ å»ºè®®æªæ–½:")
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. [{rec['priority']}] {rec['action']}")
            print(f"      åŸå› : {rec['reason']}")
            print(f"      é¢„è®¡æ—¶é—´: {rec['estimated_time']}")
            print()
        
        return recommendations

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥ç³»ç»Ÿ")
    print("=" * 60)
    
    validator = DatabaseValidator()
    report = validator.generate_validation_report()
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_file = f"data_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("ğŸ¯ ä¸“ä¸šç™¾ä¸‡çº§æ•°æ®ç”Ÿæˆè„šæœ¬ç¡®è®¤:\n")
            f.write("   è„šæœ¬åç§°: generate_real_million_data_simplified.py\n")
            f.write("   è„šæœ¬ç‰¹ç‚¹: å†…å­˜ä¼˜åŒ–ã€æ‰¹å¤„ç†ã€çœŸå®æ•°æ®ç”Ÿæˆã€é”™è¯¯å¤„ç†\n")
            f.write("   ç›®æ ‡è§„æ¨¡: 800,000å­¦ç”Ÿ + 50,000æ•™å¸ˆ + 30,000è¯¾ç¨‹ + 200,000é€‰è¯¾è®°å½•\n")
            f.write("   é¢„æœŸæ€»é‡: 1,080,000+ æ¡è®°å½•\n\n")
            
            f.write("ğŸ“Š å½“å‰æ•°æ®çŠ¶æ€:\n")
            if hasattr(validator, 'stats') and validator.stats:
                for key, value in validator.stats.items():
                    f.write(f"   {key}: {value}\n")
            
            f.write("\nğŸ’¡ å»ºè®®çš„è¿ç§»æ–¹å¼:\n")
            f.write("   ä½¿ç”¨ä¸“ä¸šè„šæœ¬ generate_real_million_data_simplified.py\n")
            f.write("   è¯¥è„šæœ¬æ˜¯é¡¹ç›®ä¸­ç»è¿‡å„ç§è€ƒé‡çš„ä¸“ä¸šç™¾ä¸‡çº§æ•°æ®ç”Ÿæˆæ–¹æ¡ˆ\n")
        
        print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
    except Exception as e:
        print(f"âš ï¸ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
    
    print("\nğŸ‰ æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥å®Œæˆï¼")
    return True

if __name__ == '__main__':
    main()